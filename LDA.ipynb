{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55eb244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cea75ae",
   "metadata": {},
   "source": [
    "# Difference in metabolomic profile at T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7d401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = pd.read_excel('T-One.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = d.drop('Group', axis=1)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df1)\n",
    "X = pd.DataFrame(scaled_data, columns=df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b7823",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = d['Group'].replace({'8°C': 0, '15°C/Control': 1, '22°C': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96935d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "\n",
    "k_best = SelectKBest(score_func=f_classif, k='all')\n",
    "fit = k_best.fit(X, y)\n",
    "\n",
    "# Get feature scores and names\n",
    "feature_scores = pd.DataFrame({'Feature': X.columns, 'Score': fit.scores_})\n",
    "feature_scores = feature_scores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "# Visualize feature scores\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.barplot(x='Score', y='Feature', data=feature_scores)\n",
    "plt.title('Feature Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae176f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = feature_scores['Feature'].head(8).tolist()\n",
    "x = X[features_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)  # You can choose the number of components\n",
    "\n",
    "# Fit PCA to your data and transform it\n",
    "X_pca = pca.fit_transform(x)\n",
    "\n",
    "X = pd.DataFrame(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8aab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train, X_test, y_train, y_test are your training and test sets\n",
    "\n",
    "# Initialize LDA model\n",
    "lda = LDA(n_components=2)\n",
    "lda.fit(X_train.iloc[:, :2], y_train)   # Train LDA model using only the first two features of X_train\n",
    "\n",
    "# Predict class labels for the test set\n",
    "y_pred = lda.predict(X_train.iloc[:, :2])\n",
    "\n",
    "# Create a meshgrid to plot the decision boundary\n",
    "x_min, x_max = X_train.iloc[:, 0].min() - 1, X_train.iloc[:, 0].max() + 1\n",
    "y_min, y_max = X_train.iloc[:, 1].min() - 1, X_train.iloc[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                     np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "# Predict the class labels for each point in the meshgrid\n",
    "Z = lda.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "\n",
    "# Plot the class distributions (scatter plot)\n",
    "markers = ['o', 's', '^']  # Example marker symbols for each class\n",
    "colors = ['red', 'blue', 'green']  # Example colors for each class\n",
    "for class_label in np.unique(y_train):  # Use y_test for plotting\n",
    "    class_indices = np.where(y_train == class_label)[0]\n",
    "    plt.scatter(X_train.iloc[class_indices, 0], X_train.iloc[class_indices, 1], marker=markers[class_label], color=colors[class_label], label=f'Class {class_label}')\n",
    "# Add legend and labels\n",
    "plt.legend()\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.title('LDA with Decision Boundary and Class Overlap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aacdb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train data accuracy\n",
    "y_train_pred = lda.predict(X_train.iloc[:, :2])  # Predict on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)  # Compute accuracy\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Test data accuracy\n",
    "y_test_pred = lda.predict(X_test.iloc[:, :2])  # Predict on test data\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)  # Compute accuracy\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccbe1c2",
   "metadata": {},
   "source": [
    "# Difference in metabolomic profile at T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0deaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2 = pd.read_excel('C:/Users/onifa/Downloads/rest/T-Two.xlsx')\n",
    "# use cytokin/metabolites significantly altered after immersion\n",
    "selected = ['IL-11 (39)_T1', 'IL-26 (22)_T1', 'gp130/sIL-6Rb (14)_T1', 'MMP-1 (43)_T1', 'Valine (2TMS)', 'Arachidonic acid, TMS derivative',\n",
    "            'Dodecanoic acid, TMS derivative', 'Indole-3-Latic Acid (3TMS)', 'L-Aspartic acid, 2TMS derivative', 'IL-35 (34)_T1',\n",
    "            'Aminomalonic acid, tris(trimethylsilyl)-', 'L-Norvaline, 2TMS derivative', 'Oxalic acid, 2TMS derivative']\n",
    "df = df2[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b722ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "X = pd.DataFrame(scaled_data, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a40623",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2['Group'].replace({'8°C': 0, '15°C/Control': 1, '22°C': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d146e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "\n",
    "k_best = SelectKBest(score_func=f_classif, k='all')\n",
    "fit = k_best.fit(X, y)\n",
    "\n",
    "# Get feature scores and names\n",
    "feature_scores = pd.DataFrame({'Feature': X.columns, 'Score': fit.scores_})\n",
    "feature_scores = feature_scores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "# Visualize feature scores\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.barplot(x='Score', y='Feature', data=feature_scores)\n",
    "plt.title('Feature Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ef404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = feature_scores['Feature'].head(9).tolist()\n",
    "x = X[features_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e5cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)  \n",
    "\n",
    "# Fit PCA to data and transform \n",
    "X_pca = pca.fit_transform(x)\n",
    "\n",
    "X = pd.DataFrame(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35711e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e84a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train, X_test, y_train, y_test are  training and test sets\n",
    "\n",
    "# Initialize LDA model\n",
    "lda = LDA(n_components=2)\n",
    "lda.fit(X_train.iloc[:, :2], y_train)   # Train LDA model using only the first two features of X_train\n",
    "\n",
    "# Predict class labels for the test set\n",
    "y_pred = lda.predict(X_train.iloc[:, :2])\n",
    "\n",
    "# Create a meshgrid to plot the decision boundary\n",
    "x_min, x_max = X_train.iloc[:, 0].min() - 1, X_train.iloc[:, 0].max() + 1\n",
    "y_min, y_max = X_train.iloc[:, 1].min() - 1, X_train.iloc[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                     np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "# Predict the class labels for each point in the meshgrid\n",
    "Z = lda.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "# Plot the decision boundary\n",
    "plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "\n",
    "# Plot the class distributions (scatter plot)\n",
    "markers = ['o', 's', '^']  # Example marker symbols for each class\n",
    "colors = ['red', 'blue', 'green']  # Example colors for each class\n",
    "for class_label in np.unique(y_train):  # Use y_test for plotting\n",
    "    class_indices = np.where(y_train == class_label)[0]\n",
    "    plt.scatter(X_train.iloc[class_indices, 0], X_train.iloc[class_indices, 1], marker=markers[class_label], color=colors[class_label], label=f'Class {class_label}')\n",
    "# Add legend and labels\n",
    "plt.legend()\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.title('LDA with Decision Boundary and Class Overlap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783a2893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train data accuracy\n",
    "y_train_pred = lda.predict(X_train.iloc[:, :2])  # Predict on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)  # Compute accuracy\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Test data accuracy\n",
    "y_test_pred = lda.predict(X_test.iloc[:, :2])  # Predict on test data\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)  # Compute accuracy\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
